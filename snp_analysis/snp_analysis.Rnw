%% SNP calling from VARSCAN output

<<snp, echo=FALSE, results=hide, cache=TRUE>>=

read.var <- function (path) {
  VAR <- read.delim(path, header=FALSE, as.is=TRUE)
  names(VAR) <- c("contig", "base", "from", "to", "nfrom", "nto", "perc", "sfrom", "sto", "qfrom", "qto", "pval")
  VAR$perc <- as.numeric(gsub("%", "", VAR$perc))
  ## Not a iupac ambiguity in reference
  ## this was not the case anyways 
  VAR <- subset(VAR, VAR$from%in%c("A", "C", "G", "T"))
  ## Reference not wrong
  VAR$nfrom <- as.numeric(as.character(VAR$nfrom))
  VAR <- subset(VAR, VAR$nfrom>1)
  VAR <- VAR[1:12]
### remove snps looking like multiple allele
  combined <- paste(VAR$contig, VAR$base)
  VAR <- VAR[! combined %in% combined[duplicated(combined)],]
  return(VAR)
}



VAR <- read.var ("/home/ele/Data/454/mapping/all_vs_full_imputed_uq.varsnp")
## ## screen for fish and bacterial contamination
## VAR <- VAR[VAR$contig%in%nematode.contig.df$contig,]
## ## use only the good category
## VAR <- VAR[VAR$contig%in%MN,]

## reduce to get only the sure Ac 
VAR <- VAR[VAR$contig%in%contig.df[contig.df$Ac, "contig"], ]

VAR <- merge(VAR, imputed)

factors <- c("contig", "from", "to", "method")
numerics <- c("base", "nfrom", "nto", "perc", "sfrom", "sto", "qfrom", "qto", "pval", "starts", "end")

VAR[, factors] <- lapply(VAR[, factors], as.factor)
VAR[, numerics] <- lapply(VAR[, numerics], function(x) as.numeric(as.character(x)))
VAR[, "mstrand"] <- as.logical(VAR[, "mstrand"])


VAR$inORF <- as.factor(VAR$base>VAR$starts & VAR$base<VAR$end)

## Exclude all snps in contigs without prediction: 
VAR <- VAR[!is.na(VAR$inORF),]

frame <- sapply(1:nrow(VAR), function (i){
  if (VAR[i,"mstrand"]){
    (VAR[i,"end"]-VAR[i,"base"])%%3
  }
  else {
    (VAR[i,"base"]-VAR[i,"starts"])%%3
  }
})
  
VAR$inFRAME <- as.factor(frame+1)
VAR[!as.logical(VAR$inORF), "inFRAME"] <- NA

transversion.transition <- function (VARobj){
  get.trans <- function (x) {
    trans <- summary(x$from:x$to)
    trans <- trans[trans!=0]
  }
  transf <- get.trans(VARobj)
  get.vers <- function (x){
    transitions <- c("A:G", "G:A", "C:T", "T:C")
    sition <- sum(x[names(x)%in%transitions])
    version <- sum(x[!names(x)%in%transitions])
    res <- cbind(transitions=sition, transversions=version, ratioTS.TV=sition/version)
    return(as.data.frame(res))
  }
  get.vers(transf)
}

find.homopolymers <- function (VARobj, width=5, size=4){
  su <- vector(length=nrow(VARobj))
  for (b in 1:nrow(VARobj)){
    su[b] <- substr(VARobj[b, "imp"], VARobj[b, "base"]-width, VARobj[b, "base"]+width)
  }
  regex <- paste("\\.*T{", size, ",}|A{", size, ",}|G{", size, ",}|C{", size, ",}\\.*", sep="")
  homopol <- sapply(su, function (x) grepl(regex, x , ignore.case=TRUE))
  names(homopol) <- su
  return(homopol)
}

## Look through the ratios of transversion vs. transition to find an
## optimal exclusion space for width of the window and size of the
## homopolymer

TS.TV <- lapply (3:9,  function(width) {
  lapply (3:6,  function (size) {
    transversion.transition(VAR[!find.homopolymers(VAR, width=width, size=size), ])
  })
})


T <- melt(TS.TV, id=c("transitions", "transversions", "ratioTS.TV"))
T <- rename(T, c(L2="size", L1="width"))
T$width <- T$width+2
T$size <- T$size+2

## How the ratio of transv-transs changes of parameterspace in homopolymer exclusion

trans.vers.parameter.plot <- ggplot(T, aes(ratioTS.TV,
                                           transversions+transitions,
                                           shape=as.factor(size),
                                           color=as.factor((width*2)+1))) +
  geom_point(size=4 ) +
  geom_smooth(aes(group = size<4), se=FALSE, method="lm") +
  scale_x_continuous("ratio transistions/transversions (ti/tv)", legend=FALSE) +
  scale_y_continuous("total numter of snps found", legend=FALSE,
                     breaks=3:10*1000,  limits=c(2500, 11000)) +
  scale_color_discrete("width of screening\nwindow around snp", legend=FALSE) +
  scale_shape_discrete("homopolymer length\nthreshold for exclusion", legend=FALSE) +
  theme_bw()

##  opts(title="Effect of parameters for homopolymer\nexclusion on the number of snps found and transversion/transition ratio")

## ## BASE ONTOLOGY
## #
## # Code from Mark Blaxter, modified by John Davey,
## # Translated from Perl to R by Emanuel Heitlinger:

## # A phase 1 any change is nonsynonymous
## # B phase 2 any change is nonsynonymous
## # C phase 3 any change is nonsynonymous
## # D phase 1 change to CT is nonsynonymous
## # E phase 2 change to CT is nonsynonymous
## # F phase 3 change to CT is nonsynonymous
## # G phase 1 change to AG is nonsynonymous
## # H phase 2 change to AG is nonsynonymous
## # I phase 3 change to AG is nonsense
## # K phase 1 change to GT is nonsynonymous
## # L phase 2 change to A is nonsense, to anything else is nonsynonymous
## # J phase 3 change to G is nonsynonymous
## # M phase 3 change to G is nonsense, to A is nonsynonymous
## # N phase 3 any change synonymous
## # O phase 1 change to T nonsense, others nonsynonymous
## # P phase 3 change to AG is nonsynonymous
## # Q phase 1 change to T nonsense, to G nonsynonymous
## # R phase 2 change to AG nonsense, others nonsynonymous
## # S phase 3 change to A nonsense, others nonsynonymous
## # T phase 3 change to A nonsense, G nonsynonymous

## # W all changes are unknown # EH added 08/23/2011

## #        a           g           c           t
## #
## # a     aaa K OBF   aga R QBF   aca T ABN   ata I ABJ
## #       aag K OBF   agg R KBF   acg T ABN   atg M ABC
## #       aac N ABP   agc S ABP   acc T ABN   atc I ABJ
## #       aat N ABP   agt S ABP   act T ABN   att I ABJ
## #
## # g     gaa E OBF   gga G OBN   gca A ABN   gta V ABN
## #       gag E OBF   ggg G ABN   gcg A ABN   gtg V ABN
## #       gac D ABP   ggc G ABN   gcc A ABN   gtc V ABN
## #       gat D ABP   ggt G ABN   gct A ABN   gtt V ABN
## #
## # c     caa Q OBF   cga R QBN   cca P ABN   cta L GBN
## #       cag Q OBF   cgg R KBN   ccg P ABN   ctg L GBN
## #       cac H ABP   cgc R ABN   ccc P ABN   ctc L ABN
## #       cat H ABP   cgt R ABN   cct P ABN   ctt L ABN
## #
## # t     taa * AEF   tga * AEC   tca S ARN   tta L GRF
## #       tag * ABF   tgg W ALS   tcg S ALN   ttg L GLF
## #       tac Y ABI   tgc C ABT   tcc S ABN   ttc F ABP
## #       tat Y ABI   tgt C ABT   tct S ABN   ttt F ABP


base.ontology.encode <- function(x){  
  ## # wrap in a control function for iupac and other "bad"
  ## # bases
  if (nchar(gsub("[bdefhijklmnopqrsuvwxyz]", "", x, ignore.case=TRUE)) != 3){
    return (paste(rep("W", times = nchar(x)), collapse=""))
  }
  else {
    ## # Set up Base Ontology vector
    base.ontology.encode.string = c(
      "aaa" = "OBF",
      "aag" = "OBF",
      "aac" = "ABP",
      "aat" = "ABP",
      "aga" = "QBF",
      "agg" = "KBF",
      "agc" = "ABP",
      "agt" = "ABP",
      "aca" = "ABN",
      "acg" = "ABN",
      "acc" = "ABN",
      "act" = "ABN",
      "ata" = "ABJ",
      "atg" = "ABC",
      "atc" = "ABJ",
      "att" = "ABJ",
      ##
      "gaa" = "OBF",
      "gag" = "OBF",
      "gac" = "ABP",
      "gat" = "ABP",
      "gga" = "OBN",
      "ggg" = "ABN",
      "ggc" = "ABN",
      "ggt" = "ABN",
      "gca" = "ABN",
      "gcg" = "ABN",
      "gcc" = "ABN",
      "gct" = "ABN",
      "gta" = "ABN",
      "gtg" = "ABN",
      "gtc" = "ABN",
      "gtt" = "ABN",
      ##
      "caa" = "OBF",
      "cag" = "OBF",
      "cac" = "ABP",
      "cat" = "ABP",
      "cga" = "QBN",
      "cgg" = "KBN",
      "cgc" = "ABN",
      "cgt" = "ABN",
      "cca" = "ABN",
      "ccg" = "ABN",
      "ccc" = "ABN",
      "cct" = "ABN",
      "cta" = "GBN",
      "ctg" = "GBN",
      "ctc" = "ABN",
      "ctt" = "ABN",
    ##
      "taa" = "AEF",
      "tag" = "ABF",
      "tac" = "ABI",
      "tat" = "ABI",
      "tga" = "AEC",
      "tgg" = "ALS",
      "tgc" = "ABT",
      "tgt" = "ABT",
      "tca" = "ARN",
      "tcg" = "ALN",
      "tcc" = "ABN",
      "tct" = "ABN",
      "tta" = "GRF",
      "ttg" = "GLF",
      "ttc" = "ABP",
      "ttt" = "ABP"
      );
    return(base.ontology.encode.string[x])
  }
}
  
base.ontology.decode = list(
  "A" = c("A" = "Nonsynonymous",  "C" = "Nonsynonymous",
    "G" = "Nonsynonymous",  "T" = "Nonsynonymous" ),
  "B" = c("A" = "Nonsynonymous",  "C" = "Nonsynonymous",
    "G" = "Nonsynonymous",  "T" = "Nonsynonymous" ),
  "C" = c( "A" = "Nonsynonymous",  "C" = "Nonsynonymous",
    "G" = "Nonsynonymous",  "T" = "Nonsynonymous" ),
  "D" = c( "A" = "Synonymous", "C" = "Nonsynonymous",
    "G" = "Synonymous", "T" = "Nonsynonymous" ),
  "E" = c( "A" = "Synonymous", "C" = "Nonsynonymous",
    "G" = "Synonymous", "T" = "Nonsynonymous" ),
  "F" = c( "A" = "Synonymous", "C" = "Nonsynonymous",
    "G" = "Synonymous", "T" = "Nonsynonymous" ),
  "G" = c( "A" = "Nonsynonymous",  "C" = "Synonymous",
    "G" = "Nonsynonymous",  "T" = "Synonymous" ),
  "H" = c( "A" = "Nonsynonymous",  "C" = "Synonymous",
    "G" = "Nonsynonymous",  "T" = "Synonymous" ),
  "I" = c( "A" = "Nonsense",  "C" = "Synonymous",
    "G" = "Nonsense",  "T" = "Synonymous" ),
  "J" = c( "A" = "Synonymous", "C" = "Synonymous",
    "G" = "Nonsynonymous",  "T" = "Synonymous" ),
  "K" = c( "A" = "Synonymous", "C" = "Synonymous",
    "G" = "Nonsynonymous",  "T" = "Nonsynonymous" ),
  "L" = c( "A" = "Nonsense",  "C" = "Nonsynonymous",
    "G" = "Nonsynonymous",  "T" = "Nonsynonymous" ),
  "M" = c( "A" = "Nonsynonymous",  "C" = "Synonymous",
    "G" = "Nonsense",  "T" = "Synonymous" ),
  "N" = c( "A" = "Synonymous", "C" = "Synonymous",
    "G" = "Synonymous", "T" = "Synonymous" ),
  "O" = c( "A" = "Nonsynonymous",  "C" = "Nonsynonymous",
    "G" = "Nonsynonymous",  "T" = "Nonsense" ),
  "P" = c( "A" = "Nonsynonymous",  "C" = "Synonymous",
    "G" = "Nonsynonymous",  "T" = "Synonymous" ),
  "Q" = c( "A" = "Synonymous", "C" = "Synonymous",
    "G" = "Nonsynonymous",  "T" = "Nonsense" ),
  "R" = c( "A" = "Nonsense",  "C" = "Nonsynonymous",
    "G" = "Nonsense",  "T" = "Nonsynonymous" ),
  "S" = c( "A" = "Nonsense",  "C" = "Nonsynonymous",
    "G" = "Nonsynonymous",  "T" = "Nonsynonymous" ),
  "T" = c( "A" = "Nonsense",  "C" = "Synonymous",
    "G" = "Nonsynonymous",  "T" = "Synonymous" ),
  "X" = c( "A" = "Nonsense",  "C" = "Nonsense",
    "G" = "Nonsense",  "T" = "Nonsense" ),
  "W" = c("A" = NA,  "C" = NA,
    "G" = NA, "T" = NA , "R" = NA,
    "Y" = NA, "S" = NA, "W" = NA,
    "K" = NA, "M" = NA, "B" = NA,
    "D" = NA, "H" = NA, "V" = NA,
    "N" = NA, "X" = NA),
  "Y" = c("A" = "low coverage",  "C" = "low coverage",
    "G" = "low coverage", "T" = "low coverage" , "R" = "low coverage",
    "Y" = "low coverage", "S" = "low coverage", "W" = "low coverage",
    "K" = "low coverage", "M" = "low coverage", "B" = "low coverage",
    "D" = "low coverage", "H" = "low coverage", "V" = "low coverage",
      "N" = "low coverage", "X" = "low coverage"),
  "Z" = c("A" = "outside ORF",  "C" = "outside ORF",
    "G" = "outside ORF", "T" = "outside ORF" , "R" = "outside ORF",
    "Y" = "outside ORF", "S" = "outside ORF", "W" = "outside ORF",
    "K" = "outside ORF", "M" = "outside ORF", "B" = "outside ORF",
    "D" = "outside ORF", "H" = "outside ORF", "V" = "outside ORF",
    "N" = "outside ORF", "X" = "outside ORF")
  );


get.ontology <- function (contig.df.obj){
  coding <- ifelse(!is.na(contig.df.obj$mstrand) &
                   as.logical(contig.df.obj$mstrand),  
                   ## revcom to get the sequence on the plus strand always
                   ## sometimes, there are Ns after the end of orfs!!
                   revcom (gsub("[ACGTRYSWKMBDHVNX]", "", contig.df.obj$imp)),
                   gsub("[ACGTRYSWKMBDHVNX]", "", contig.df.obj$imp)
                   )
  codons <- lapply(coding, function (co){
    if (nchar(co)==0) {co <- "NNN"}
    if(nchar(co)%%3!=0) {
      co <- paste(rep("NNN", times=ceiling(nchar(co)/3)), collapse="")
    }
    substring(co, seq(1, nchar(co), by=3), seq(3,nchar(co), by=3))})
  ontology <- lapply(codons, function (x) { sapply (x, base.ontology.encode)})
  ontology <- as.character(sapply(ontology, paste, collapse=""))
   ## reverse back to be able to use normal snp cooridingates
  ontology <- ifelse(as.logical(contig.df.obj$mstrand),
                     strReverse(ontology),
                     ontology)
  E <- lapply(contig.df.obj$imp, function (x) {
    ends <- strsplit(x, "[a-z]+")
    if (length(ends)==2){return(c(gsub(".", "Z", ends)))}
    if (length(ends)==1){return(c(gsub(".", "Z", ends[[1]]), ""))}
    return(ends)
  })
  ontology <- unlist(lapply(1:length(ontology), function(i){
    paste(E[[i]][[1]], ontology[[i]], E[[i]][[2]], sep="")}))
}

get.sites <- function (ontology, imputed){
  s.sites <- sapply(1:length(ontology), function (i) {
     split.ont <- unlist(strsplit(ontology[[i]], ""))
     split.cod <- unlist(strsplit(imputed[[i]], ""))
     decoded <- lapply(split.ont, function (a){
       base.ontology.decode[[a]]})
     reduced.decoded <- lapply(1:length(decoded), function (x) {
       subset(decoded[[x]], names(decoded[[x]])!=toupper(split.cod[[x]]))})
     s <- lapply(reduced.decoded, function (w) {
       length(w[grepl("Syn", w)])/length(w[grepl("Syn|Non", w)])})
     n <- lapply(reduced.decoded, function (w) {
       length(w[grepl("Non", w)])/length(w[grepl("Syn|Non", w)])})
     nsyn.sites <- sum(unlist(n), na.rm=TRUE)
     syn.sites <- sum(unlist(s), na.rm=TRUE)
     cbind(nsyn.sites, syn.sites)
   })
  data.frame(t(s.sites))
}

contig.df$ontology <- get.ontology(contig.df)
## ugly fix non predicted
contig.df[nchar(contig.df$ontology)!=nchar(contig.df$imp), "ontology"] <-
  gsub(".", "Z", contig.df[nchar(contig.df$ontology)!=nchar(contig.df$imp), "imp"])

## get the coding region coverd >8x in snp calling
imp.cov.pile <- imp.pile[imp.pile$imputed.coverage>7, ]
b <- by(imp.cov.pile, imp.cov.pile$contig,
        function (x) c(x[1,"base"], x[nrow(x), "base"]))
cov.8.borders <- as.data.frame(do.call("rbind", b))
names(cov.8.borders) <- c("cov.8.start", "cov.8.stop")
contig.df <- merge(contig.df, cov.8.borders,
                   by.x="contig", by.y="row.names", all.x=TRUE)

## get a coverage informed ontology:
contig.df$cov.ontology <- apply(contig.df, 1, function (x) {
  if(is.na(as.numeric(x["cov.8.start"]))){
    return(gsub(".", "Y", x["ontology"]))}
  bef <- substr(x["ontology"],
                1, as.numeric(x["cov.8.start"])-1)
  bef <- gsub(".", "Y", bef)
  ont <- substr(x["ontology"],
                as.numeric(x["cov.8.start"]),
                as.numeric(x["cov.8.stop"]))
  aft <- substr(x["ontology"],
                as.numeric(x["cov.8.stop"])+1,
                nchar(x["ontology"]))
  aft <- gsub(".", "Y", aft)
  paste(bef, ont, aft, sep="")
})


SITES <- get.sites(contig.df$ontology, contig.df$imp)
names(SITES) <- c("nsyn.sites", "syn.sites")

COV.SITES <- get.sites(contig.df$cov.ontology, contig.df$imp)
names(COV.SITES) <- c("cov8.nsyn.sites", "cov8.syn.sites")

contig.df <- cbind(contig.df, SITES)
contig.df <- cbind(contig.df, COV.SITES)

VAR <- merge(VAR, contig.df[,c("contig", "ontology", "nsyn.sites", "syn.sites", "cov8.nsyn.sites", "cov8.syn.sites")] )


get.effect <- function (ontology, base, to){
  code <- unlist(strsplit(ontology, ""))[[base]]
  base.ontology.decode[[code]][[to]]
}

VAR$effect <- apply(VAR, 1, function(x){
  get.effect(x["ontology"], as.numeric(x["base"]), x["to"])
})
  
get.dn.ds <- function(VARobj){
  (nrow(VARobj[grepl("Non*", VARobj$effect),])/
   sum(VARobj[!duplicated(VARobj$contig), "cov8.nsyn.sites"], na.rm=T))/
  (nrow(VARobj[VARobj$effect=="Synonymous",])/
   sum(VARobj[!duplicated(VARobj$contig), "cov8.syn.sites"], na.rm=T))}
  
## Look through the overall dn/ds to find an
## optimal exclusion space for width of the window and size of the
## homopolymer

O.DN.DS <- sapply (3:9,  function(width) {
  sapply (3:6,  function (size) {
    get.dn.ds(VAR[!find.homopolymers(VAR, width=width, size=size), ])
  })
})


D <- melt(O.DN.DS)
names(D)[1:2] <- c("size", "width")
D$width <- D$width+2
D$size <- D$size+2
T <- merge(D, T)
T <- rename(T, replace=c(value="dn.ds"))

dn.ds.parameter.plot <- ggplot(T, aes(dn.ds,
                                      transversions+transitions,
                                      shape=as.factor(size),
                                      color=as.factor(width*2+1))) +
  geom_point(size=4) +
  geom_smooth(aes(group = size<4), se=FALSE, method="lm") +
  scale_x_reverse("ratio non-synonymous/synonymous snps (dn/ds)") +
  scale_y_continuous("", breaks=3:10*1000, labels=rep("",8), limits=c(2500, 11000)) +
  scale_color_discrete("width of screening\nwindow around snp") +
  scale_shape_discrete("homopolymer length\nthreshold for exclusion") +
  theme_bw()

                               ## opts(title="Effect of parameters for
                               ## homopolymer\nexclusion on the number
                               ## of snps found and\nratio of non-synonymous/synonymous snps")

#### Decided on the SNP sequence quality-screening
VARq <- (VAR[!find.homopolymers(VAR),])

#### Now consider mapping quality
VARq.plot <- VARq
VARq.plot$perc[VARq.plot$perc>50] <- 51

position.perc.plot <- ggplot(VARq.plot[!is.na(VARq.plot$inFRAME),], aes(x = perc, fill = inFRAME)) +
  stat_bin(binwidth=1, color="black", breaks=seq(0, 52, by=2),
           position=position_dodge(width=(1.4))) +
  scale_x_continuous("percent of minority allele", 
                     breaks= seq(0, 52, by=2),
                     labels = c(seq(0, 48, by=2), ">50", "")) +
  scale_y_continuous("number of snps found") +
  scale_fill_discrete("position in frame") +
  theme_bw()


effect.perc.plot <- ggplot(VARq.plot[!is.na(VARq.plot$effect),], aes(x = perc, fill = effect)) +
  stat_bin(binwidth=1, color="black", breaks=seq(0, 52, by=2),
           position=position_dodge(width=c(1.7))) +
  scale_x_continuous("percent of minority allele",
                     breaks= seq(0, 52, by=2),
                     labels = c(seq(0, 48, by=2), ">50", "")) +
  scale_y_continuous("number of snps found") +
  scale_fill_discrete("effect of snp") +
  theme_bw()


VARq.plot$fromto <- VARq.plot$nfrom + VARq.plot$nto
VARq.plot$fromto[VARq.plot$fromto>100] <- 101

position.cov.plot <- ggplot(VARq.plot[!is.na(VARq.plot$inFRAME),], aes(x = fromto, fill = inFRAME)) +
  stat_bin(binwidth=1, color="black", breaks=seq(0, 105, by=5),
           position=position_dodge(width=(2.8))) +
  scale_x_continuous("coverage at snp positon",
                     breaks = seq(0, 105, by=5),
                     labels = c(seq(0, 95, by=5), ">100", "")) +
  scale_y_continuous("number of snps found") +
  scale_fill_discrete("position in frame") +
  theme_bw()

effect.cov.plot <- ggplot(VARq.plot[!is.na(VARq.plot$effect),], aes(x = fromto, fill = effect)) +
  stat_bin(binwidth=1, color="black", breaks=seq(0, 105, by=5),
           position=position_dodge(width=(2.8))) +
  scale_x_continuous("coverage at snp positon",
                     breaks = seq(0, 105, by=5),
                     labels = c(seq(0, 95, by=5), ">100", "")) +
  scale_y_continuous("number of snps found") +
  scale_fill_discrete("effect of snp") +
  theme_bw()

#### discard snps with <7% minority allel
VARqp <- VARq[VARq$perc>7, ]

## Without screening the percentage

TSVs <- do.call("rbind",
                     by(VARq,
                        VARq$contig,
                        function (x) transversion.transition(x)))

contig.df.wo <- merge(contig.df, TSVs, by.x="contig", by.y="row.names", all.x=TRUE)

N.by.S <- by(VARq, VARq$contig, get.dn.ds)
contig.df.wo <- merge(contig.df.wo, t(as.data.frame.list(N.by.S)), by.x="contig", by.y="row.names", all.x=TRUE)
names(contig.df.wo)[ncol(contig.df.wo)] <- "dn.ds"
contig.df.wo$dn.ds[is.infinite(contig.df.wo$dn.ds)] <- NA

sy.per <- as.data.frame(rbind(table(VARq$contig, VARq$effect)))

contig.df.wo <- merge(contig.df.wo, sy.per, by.x="contig", by.y="row.names", all.x=TRUE)

dn.ds.coverage.plot.wo <- ggplot(contig.df.wo, aes(x = dn.ds, y= imputed.coverage)) +
  geom_point() +
  scale_y_log10("coverage of TUG") +
  scale_x_continuous("ratio non-synonymous/synonymous snps (dn/ds)", breaks=1:8/2, limits=c(0,4)) + 
  stat_smooth(method="lm") +
  theme_bw()

cov.lm.raw <- summary(lm(dn.ds ~ imputed.coverage, data=contig.df.wo))

dn.ds.total.snps.plot.wo <- ggplot(contig.df.wo, aes(y=transversions+transitions, x=dn.ds)) +
  geom_point() +
  scale_y_continuous("total number of snps in contig") +
  stat_smooth(method="lm") +
  theme_bw()


## With screening the percentage

TSVs <- do.call("rbind",
                     by(VARqp,
                        VARqp$contig,
                        function (x) transversion.transition(x)))

contig.df <- merge(contig.df, TSVs, by.x="contig", by.y="row.names", all.x=TRUE)


N.by.S <- by(VARqp, VARqp$contig, get.dn.ds)
contig.df <- merge(contig.df, t(as.data.frame.list(N.by.S)), by.x="contig", by.y="row.names", all.x=TRUE)
names(contig.df)[ncol(contig.df)] <- "dn.ds"
contig.df$dn.ds[is.infinite(contig.df$dn.ds)] <- NA

sy.per <- as.data.frame(rbind(table(VARqp$contig, VARqp$effect)))

contig.df <- merge(contig.df, sy.per, by.x="contig", by.y="row.names", all.x=TRUE)

dn.ds.coverage.plot <- ggplot(contig.df, aes(x = dn.ds, y= imputed.coverage)) +
  geom_point() +
  scale_y_log10("coverage of TUG") +
  scale_x_continuous("ratio non-synonymous/synonymous snps (dn/ds)", breaks=1:8/2, limits=c(0,4)) +
  stat_smooth(method="lm") +
  theme_bw()

cov.lm <- summary(lm(dn.ds ~ imputed.coverage, data=contig.df))

dn.ds.total.snps.plot <- ggplot(contig.df, aes(y=transversions+transitions, x=dn.ds)) +
  geom_point() +
  scale_y_continuous("total number of snps in contig") +
  stat_smooth(method="lm") +
  theme_bw()


### The contigs looking like TS.TV~30 are the infinite values!

dens.dn.ds <- ggplot(contig.df[!is.na(contig.df$dn.ds),],
                     aes(dn.ds, ..count..)) + geom_bar(binwidth=0.1) +
  theme_bw()



## no need to  beta calc from http://www.biomedcentral.com/1471-2164/11/310
## and the original idea http://www.biomedcentral.com/1471-2164/9/312

@ 

<<echo=FALSE, results=hide>>=

pdf("../figures/Figure_3.pdf", width=10, height=5)

# Set up the page
grid.newpage()
pushViewport(viewport(layout = grid.layout(1, 2)))

vp1 <- viewport(width = 0.46,  height=0.98, x = 0.22, y = 0.5)
vp2 <- viewport(width = 0.56,  height=0.98, x = 0.73, y = 0.5)

# Make each plot, in the correct location
print(trans.vers.parameter.plot, vp = vp1)
print(dn.ds.parameter.plot, vp = vp2)
grid.text("a", x=unit(0.01,"npc"), y=unit(0.98,"npc")) 
grid.text("b", x=unit(0.46,"npc"), y=unit(0.98,"npc")) 

dev.off() 

pdf("../figures/Figure_4.pdf", width=25, height=15)
# Set up the page
grid.newpage()
pushViewport(viewport(layout = grid.layout(2, 2)))
vplayout <- function(x, y)
    viewport(layout.pos.row = x, layout.pos.col = y)

# Make each plot, in the correct location
print(position.perc.plot, vp = vplayout(1, 1 ))
print(effect.perc.plot, vp = vplayout(2, 1 ))
print(dn.ds.coverage.plot.wo, vp = vplayout(1, 2 ))
print(dn.ds.coverage.plot, vp = vplayout(2, 2 ))

grid.text("a", x=unit(0.01,"npc"), y=unit(0.99,"npc")) 
grid.text("b", x=unit(0.51,"npc"), y=unit(0.99,"npc")) 
grid.text("c", x=unit(0.01,"npc"), y=unit(0.52,"npc")) 
grid.text("d", x=unit(0.51,"npc"), y=unit(0.52,"npc")) 

dev.off() 

ggsave("../figures/dens_dn_ds.pdf", dens.dn.ds)

@ 


<<snps.again, echo=FALSE, cache=TRUE>>=


nCov8bases <- nrow(imp.pile[imp.pile$contig%in%contig.df[contig.df$Ac, "contig"] &
                            imp.pile$imputed.coverage>7, ])

nrawOrf <- tapply(VAR$inORF, VAR$inORF, length)
nrawFrame <- tapply(VAR$inFRAME, VAR$inFRAME, length)

raw.ts.tv <- transversion.transition(VAR)
tsv.raw.orf <- round(do.call(rbind, by(VAR, VAR$inORF, transversion.transition)), 2)
raw.dn.ds <- round(get.dn.ds(VAR), 2)


s.base <- sum(contig.df[contig.df$Ac, "cov8.syn.sites"], na.rm=TRUE)
n.base <- sum(contig.df[contig.df$Ac, "cov8.nsyn.sites"], na.rm=TRUE)

sSNP <- sum(contig.df[contig.df$Ac, "Synonymous"], na.rm=TRUE)
nSNP <- sum(contig.df[contig.df$Ac, "Nonsynonymous"], na.rm=TRUE)

per.base <- round(nrow(VARqp)/(nCov8bases/1000), 2)

s.per.s.base <- round(sSNP/(s.base/1000), 2)
n.per.n.base <- round(nSNP/(n.base/1000), 2)

@ 
